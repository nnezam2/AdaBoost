{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     \n",
       "final -1  1\n",
       "   -1  8  0\n",
       "   1  10  8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Testing error after using Adaboost is:  0.384615384615385'</span>"
      ],
      "text/latex": [
       "'Testing error after using Adaboost is:  0.384615384615385'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Testing error after using Adaboost is:  0.384615384615385'</span>"
      ],
      "text/plain": [
       "[1] \"Testing error after using Adaboost is:  0.384615384615385\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Loading Required Libraries\n",
    "library(stats)\n",
    "library(rpart)\n",
    "library(ISLR) \n",
    "library(tidyverse)\n",
    "library(partykit)\n",
    "\n",
    "#### Loading the data file and looking at data\n",
    "Data<-stagec\n",
    "#str(Data)\n",
    "\n",
    "#### Creating train and test set \n",
    "n<-nrow(stagec)\n",
    "train <- sample(1:n, 120)\n",
    "test <- setdiff(1:n, train)\n",
    "\n",
    "#### Implementing Adaboost algorithm\n",
    "\n",
    "## creating the status based on pgstat \n",
    "status <- factor(stagec$pgstat, levels=c(0,1), labels=c(-1,1))\n",
    "\n",
    "## initializations \n",
    "m<-length(train)\n",
    "k<-length(test)\n",
    "epsilon=0 # initialise epsilon\n",
    "alpha=0 # initialise alpha\n",
    "T<-500 #number of rounds \n",
    "Stump=matrix(data = NA, nrow = m, ncol = T) # where Stumps are to be store\n",
    "pred=matrix(data = NA, nrow = 26, ncol = T) # where Stumps are to be store\n",
    "\n",
    "## Algorithm \n",
    "for (t in seq(1:T))\n",
    "{\n",
    "    \n",
    "    # construct distribution: D_{t}(i)=D_{t-1}(i)*F_i/Z\n",
    "   if (t==1){\n",
    "      D=rep(1/m, m) # particular case, D_1\n",
    "           } \n",
    "    else\n",
    "      {\n",
    "        \n",
    "      for (i in seq(1:m)){\n",
    "          \n",
    "          if (h[i]==status[i]) { \n",
    "          F[i]=exp(-alpha[t-1]) }\n",
    "          \n",
    "            else {    \n",
    "            # F_i(for t-1)\n",
    "            F[i]=exp(alpha[t-1]) \n",
    "                  }\n",
    "          \n",
    "        # D_{t}(i)=D_{t-1}(i)*F_i/Z    \n",
    "        D[i]=D[i]*F[i] \n",
    "      }\n",
    "        \n",
    "       }\n",
    "    \n",
    "    # normalisation\n",
    "    D=D/sum(D)\n",
    "      \n",
    "\n",
    "    # fit a single classification tree\n",
    "    ctrl <- rpart.control(cp = 0, maxdepth = 1, xval = 0)\n",
    "\n",
    "    fit.rp <- rpart(factor(status[train]) ~ age + eet + g2 + grade + gleason + ploidy,\n",
    "              data = stagec[train,], method=\"class\",weights = D, control = ctrl)\n",
    "\n",
    "    # make predictions on the train data (needed for boosting)\n",
    "    h <- predict(fit.rp, newdata =stagec[train,] , type=\"class\")\n",
    "    h <- as.numeric(as.character(h))   \n",
    "    Stump[,t]<-h\n",
    "    \n",
    "    # make prediction on test set (needed for test error)\n",
    "    p <- predict(fit.rp, newdata =stagec[test,] , type=\"class\")\n",
    "    p <- as.numeric(as.character(p))   \n",
    "    pred[,t]<-p\n",
    "    \n",
    "   # compute error to get epsilon and alpha (based on train data)\n",
    "   epsilon[t]=sum(D[!(status[train] == h)])\n",
    "    \n",
    "   alpha[t]=0.5*log((1-epsilon[t])/epsilon[t]) # alpha_{t}\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "## Last step: error on test set using the boosted model \n",
    "\n",
    "final<-matrix(data = 0, nrow =k , ncol = 1)\n",
    "\n",
    "for (t in seq(1:T)){\n",
    "final=final+ alpha[t]*pred[,t]\n",
    "   }\n",
    "\n",
    "final<-sign(final)\n",
    "accuracytable<-table(final, status[test])\n",
    "accuracytable\n",
    "\n",
    "error=(accuracytable[1, 2]+accuracytable[2, 1])/k\n",
    "paste0(\"Testing error after using Adaboost is:  \",error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=white-space:pre-wrap>'Testing error after using a single classification tree is:  0.423076923076923'</span>"
      ],
      "text/latex": [
       "'Testing error after using a single classification tree is:  0.423076923076923'"
      ],
      "text/markdown": [
       "<span style=white-space:pre-wrap>'Testing error after using a single classification tree is:  0.423076923076923'</span>"
      ],
      "text/plain": [
       "[1] \"Testing error after using a single classification tree is:  0.423076923076923\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Test Error based on a single classification tree\n",
    "\n",
    "## fit a single classification tree\n",
    "fitted <- rpart(status[train] ~ age + eet + g2 + grade + gleason + ploidy,\n",
    "              data = stagec[train,], method=\"class\")\n",
    "\n",
    "## make predictions on the test data\n",
    "pred <- predict(fitted, newdata = stagec[test,], type=\"class\")\n",
    "err<- mean(status[test] != pred)  # the test error\n",
    "\n",
    "paste0(\"Testing error after using a single classification tree is:  \",err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comments:\n",
    "Based on the above, boosting improves the test error (which means we will get lower error rate ) compared with the single classification tree. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
